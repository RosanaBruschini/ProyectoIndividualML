                                                                                                                                                                                                                    *üòäLinkedin*:https://www.linkedin.com/in/robruschini/

# üïπÔ∏èüéØ ProyectoIndividualML - Trabajo como Data Scientist en Steam, una plataforma multinacional de videojuegos.üéÆ‚ú®
## Proyecto MLOps: Sistema de Recomendaci√≥n de Videojuegos  üéÆ

**Objetivo Principal**üéØ

Desarrollar un sistema de recomendaci√≥n de videojuegos para la plataforma Steam. Con el fin de mejorar la experiencia de los usuarios al sugerir juegos relevantes y atractivos

> # 1. Extracci√≥n, transformaci√≥n üßπ| An√°lisis Exploratorio de Datos|üìà 
Objetivo: Limpiar y preprocesar los archivos brindados, con datos iniciales no estructurados, comprender las relaciones entre las variables, para que sean aptos para el an√°lisis, posteiror realizaci√≥n de las funciones y entrenamiento del modelo

Dificultades: Los archivos eran muy pesados,  en formato jason.gzip, con datos anidados, alto porcentaje de None y Nan, s√≠mbolos, lo que dificultaba su manipulaci√≥n, extracci√≥n, transformaci√≥n y su an√°lisis.
(ETL)
En los tres casos, los archivos se encuentran en formato JSON comprimidos en .gz,  los cuales fueron descomprimidos antes de ser cargados a Python.
Se hizo una exploraci√≥n exhaustiva de los tres archivos para entender la estructura de los datos. Luego cada uno fue transformado en un Data Frame, para una mejor exploraci√≥n y entendimiento de la situaci√≥n, y toma de desici√≥n de tratamiento a implementar.
En consecuencia se determin√≥ realizar peque√±os DF para ser funcionales y trabajar con archivos de mejor manipulaci√≥n en tama√±o para cada funci√≥n, para lo cual, se comenz√≥ por definir las columnas requeridas. Seguidamente se desanidaron las columnas con datos considerados necesarios. En todos los casos una vez creado el nuevo Data Frame , se realiz√≥ una limpieza general (contar nulos, duplicados, datos unicos, en la mayor√≠a de los casos los nan fueron reemplazados por o y duplicados eliminados), sumado a transformaciones y an√°lisis espec√≠ficos de cada DF que se aclarar√°n a continuaci√≥n, aquellos que se consideran relevantes. Una vez concluidos los procedimeintos mencionados, fueron reducidos en un 50%, previendo su carga futura y guardados en formato csv.

**Descripc√≥n de particularidades por archivo** üåü

**User_eviews**: se extrajeron las columnas necesarias para crear un nuevo DF bajo en nombre **df_original**para trabajar las funciones 1 y 2, para lo cual se procedi√≥ a la verificaci√≥n y limpieza de nulos, Nan, duplicados, luego se dividi√≥ la columna 'posted' en nuevas columnas de d√≠a, mes y a√±o, se sum√≥ un d√≠gito a d√≠a y se redujo nuevamente a una sola columna "Fecha", la cual contiene (a√±o, mes, d√≠a) en formato Str. La columna "recomended" originalmente conteni√° valores booleanos, siendo reemplazada por int. donde true = 1 y false = o

**Steam_games**: para la funci√≥n 1 se cre√≥ el DF denominado: **df_new_game_copy**, mediante la selecci√≥n de las columnas: "price", "items_count", "user_id", convertiendo los datos en  "price" y "items_count" a tipo float y los "None" por 0 para evitar errores a la hora de contarlos o sumar como tambi√©n una mejor interpretaci√≥n de los datos.
Se crea el DF **df_new_game_copy**, para realizar la funci√≥n 3 y 4. Se procede a desanidar la columna "genre",  extrayendo los valore en columnas separadas para cada g√©nero. Luego se concatenan las columnas desanidadas de "genre" con el DF inicial. Finalmente se crea una funci√≥n  para rellenar los valores NaN en 'user_id' con valores aleatorios,  si 'app_name' no es NaN. 
Para trabajar la funci√≥n 5 se cre√≥ el DF **df_funcion5**, comenzando del archivo original se seleccionaron las columnas: release_date,	developer, y	price	items_count. Se filtran los datos en la columna price para visualizar la cantidad de  veces que aparecen: 'Free to Play', 'Free To Play', 'Free'. Por otra parte , se extrae los primeros 4 caracteres de la columna 'release_date' y se crea una nueva columna 'year'

**User_items**:
para la realizaci√≥n de la funci√≥n 3 y 4  se trabaj√≥ en la creaci√≥n del DF **df_items_ph3**. Donde se procedi√≥ a desanidar la columna "item" para extraer: item_id,	item_name,	playtime_forever	y playtime_2weeks. All√≠, playtime_forever se convierte a float y se crea una nueva columna 'playtime_hours' que permite visualizar el tiempo en  horas.
Posteriormente se hizo un merge en pandas, para combinar dos DataFrames(**df_new_games_copy, df_items_ph3**) para lograr el DF adecuado para trabajar la funcion 3 y 4 denominado df_fusion3. Logrado simplificar la manipulaci√≥n de los datos mediante con las columnas elegidas, para hacerles limpieza, transformaci√≥n, y luego ser guardados en formato csv.
Las t√©cnicas utilizadas fueron: la imputaci√≥n de valores faltantes, la eliminaci√≥n de duplicados y la detecci√≥n y tratamiento de valores at√≠picos.

# 2. Desarrollo de las funciones para la API
A partir de especificaciones dadas, como se mencion√≥ anteriormente se crearon los archivos csv contemplando las necesidades y particularidades requeridas para la construcci√≥n de cada funci√≥n. En consecuencia, se pudo comprobar el √≥ptimo funcionamiento, de cada funci√≥n mediante la obtenci√≥n de resultados l√≥gicos.

# 3. Desarrollo de la API con FastAPI üöÄ
Mediante la creaci√≥n del archivo main.py se instaur√≥ una API utilizando el framework FastAPI, permitiendo realizar consultas espec√≠ficas sobre los datos, obteniendo recomendaciones de videojuegos. Las funciones utilizadas son las desarrolladas en el punto 2, disponibles en el archivo **proyecto_funciones**.  Las consultas posibles a realizar son: informaci√≥n del usuario, contar rese√±as en un rango de fechas, buscar juegos por g√©nero, entre otras.

# 4. Despliegue de la API en la Nube ‚òÅÔ∏è
Se seleccion√≥ la plataforma Railway, para desplegar la API en un entorno accesible p√∫blicamente y poder ser utilizada, ya simplific√≥ el proceso de deployment para conectar al repositorio de GitHub .

# 5. Modelo de Aprendizaje Autom√°tico ü§ñ

Se dise√±√≥ un sistema de recomendaci√≥n basado en filtrado colaborativo que utiliza PCA (An√°lisis de Componentes Principales) y la similitud de coseno para proporcionar recomendaciones de √≠tems basadas en la similitud entre los √≠tems. El c√≥digo crea una funci√≥n que toma un √≠tem de referencia y devuelve las mejores recomendaciones para ese √≠tem en funci√≥n de la similitud de coseno.

> Mapea usuarios e √≠tems a √≠ndices enteros para procesamiento eficiente.
> Divide los datos en conjuntos de entrenamiento y prueba.
> Normaliza las caracter√≠sticas de los √≠tems y aplica PCA para reducir la dimensionalidad.
> Calcula la similitud de coseno entre √≠tems y crea una matriz de similitud.
> Define una funci√≥n para obtener recomendaciones de √≠tems basadas en la similitud.
> Utiliza la funci√≥n para obtener recomendaciones para un √≠tem de referencia.

# Link Railway: proyectoindividualml-production.up.railway.app


# Anexos

**Link drive a archivos originales**: https://drive.google.com/drive/folders/1f6SyIawen1rKy9I8YbIvnuDMYP4diBGH?usp=sharing

**Video Demostrativo**: Se adjunta video explicativo
# Detalle de librerias:
import pandas as pd
import numpy as np
import json
import matplotlib.pyplot as plt
import seaborn as sns 
import ipywidgets as widgets
import ast
import re
from sklearn.model_selection import train_test_split
from sklearn.decomposition import PCA
from sklearn.metrics.pairwise import cosine_similarity



